name: ORCID Polish Researchers Collection

on:
  schedule:
    # Run daily at 2 AM UTC (avoids peak hours)
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of researchers to process'
        required: false
        default: '6250'
        type: string
      max_api_calls:
        description: 'Maximum API calls per run'
        required: false
        default: '25000'
        type: string

# Needed to read artifacts from prior runs
permissions:
  contents: read
  actions: read

jobs:
  collect-orcid-data:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours max

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements_github.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          set -euxo pipefail
          python -m pip install --upgrade pip
          pip install -r requirements_github.txt

      - name: Ensure data directory
        run: mkdir -p data

      # Find latest non-expired artifacts by name in this repo
      - name: Find latest artifacts
        id: find_artifacts
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const owner = context.repo.owner;
            const repo = context.repo.repo;

            const artifacts = await github.paginate(
              github.rest.actions.listArtifactsForRepo,
              { owner, repo, per_page: 100 }
            );

            function latestByName(name) {
              const list = artifacts
                .filter(a => a.name === name && !a.expired)
                .sort((a, b) => new Date(b.created_at) - new Date(a.created_at));
              return list[0] || null;
            }

            const db = latestByName('polish-scientists-database');
            const ids = latestByName('polish-researchers-ids');

            core.setOutput('db_artifact_id', db ? String(db.id) : '');
            core.setOutput('ids_artifact_id', ids ? String(ids.id) : '');
            core.info(`DB artifact id: ${db ? db.id : 'none'}`);
            core.info(`IDs artifact id: ${ids ? ids.id : 'none'}`);

      - name: Download previous database
        if: steps.find_artifacts.outputs.db_artifact_id != ''
        uses: actions/download-artifact@v5
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          artifact-ids: ${{ steps.find_artifacts.outputs.db_artifact_id }}
          path: data/

      - name: Download researcher IDs file
        if: steps.find_artifacts.outputs.ids_artifact_id != ''
        uses: actions/download-artifact@v5
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          artifact-ids: ${{ steps.find_artifacts.outputs.ids_artifact_id }}
          path: data/

      - name: No previous artifacts found
        if: steps.find_artifacts.outputs.db_artifact_id == '' && steps.find_artifacts.outputs.ids_artifact_id == ''
        run: echo "No previous artifacts found (first run or artifacts expired). Continuing."

      - name: Check existing files
        run: |
          set -euxo pipefail
          echo "=== Workspace contents ==="
          ls -la
          echo "=== Data folder contents ==="
          ls -la data/ || echo "No data folder found"

          # Check database
          if [ -f "data/polish_scientists.db" ]; then
            echo "ðŸ“Š Database size: $(du -h data/polish_scientists.db)"
            echo "ðŸ“Š Database records: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Researchers;' 2>/dev/null || echo 'No Researchers table')"
          else
            echo "ðŸ“„ No existing database found"
          fi

          # Check IDs file
          if [ -f "data/polish_researchers_all.txt" ]; then
            echo "ðŸ“‹ IDs file size: $(wc -l < data/polish_researchers_all.txt) lines"
          else
            echo "ðŸ“„ No IDs file found"
          fi

      - name: Run ORCID data collection
        env:
          BATCH_SIZE: ${{ github.event.inputs.batch_size || '6250' }}
          MAX_API_CALLS: ${{ github.event.inputs.max_api_calls || '25000' }}
          DB_PATH: 'data/polish_scientists.db'
          IDS_FILE: 'data/polish_researchers_all.txt'
        run: |
          set -euxo pipefail
          echo "ðŸš€ Starting ORCID collection with batch size: $BATCH_SIZE"
          python orcid_collector_github.py

      - name: Check results
        run: |
          set -euxo pipefail
          echo "=== Collection Results ==="
          if [ -f "data/polish_scientists.db" ]; then
            echo "ðŸ“Š Final database size: $(du -h data/polish_scientists.db)"
            echo "ðŸ“Š Total researchers: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Researchers;' 2>/dev/null || echo 'Error reading database')"
            echo "ðŸ“Š Total institutions: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Institutions;' 2>/dev/null || echo 'Error reading database')"
            echo "ðŸ“Š Total publications: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Publications;' 2>/dev/null || echo 'Error reading database')"
          else
            echo "âŒ No database file found"
          fi

      - name: Upload database artifact
        uses: actions/upload-artifact@v4
        with:
          name: polish-scientists-database
          path: data/polish_scientists.db
          retention-days: 90
          if-no-files-found: warn

      - name: Upload researcher IDs artifact
        uses: actions/upload-artifact@v4
        with:
          name: polish-researchers-ids
          path: data/polish_researchers_all.txt
          retention-days: 90
          if-no-files-found: warn

      - name: Upload logs (if any)
        uses: actions/upload-artifact@v4
        with:
          name: collection-logs-${{ github.run_number }}
          path: "*.log"
          retention-days: 30
          if-no-files-found: ignore

      - name: Collection summary
        run: |
          {
            echo "## ðŸŽ¯ ORCID Collection Summary"
            echo
            if [ -f "data/polish_scientists.db" ]; then
              researchers_count=$(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Researchers;' 2>/dev/null || echo 'Unknown')
              echo "- **Researchers processed:** $researchers_count"
              institutions_count=$(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Institutions;' 2>/dev/null || echo 'Unknown')
              echo "- **Institutions:** $institutions_count"
              publications_count=$(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Publications;' 2>/dev/null || echo 'Unknown')
              echo "- **Publications:** $publications_count"
              db_size=$(du -h data/polish_scientists.db | cut -f1)
              echo "- **Database size:** $db_size"
            else
              echo "- **Status:** âŒ Collection failed - no database generated"
            fi
            echo
            echo "Next run scheduled for tomorrow at 2 AM UTC"
          } >> "$GITHUB_STEP_SUMMARY"
