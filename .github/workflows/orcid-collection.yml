name: ORCID Polish Researchers Collection

on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of researchers to process'
        required: false
        default: '6250'
        type: string
      max_api_calls:
        description: 'Maximum API calls per run'
        required: false
        default: '25000'
        type: string

# we push to the repo
permissions:
  contents: write

jobs:
  collect-orcid-data:
    runs-on: ubuntu-latest
    timeout-minutes: 360

    steps:
      # checkout main to run code
      - name: Checkout repository (main)
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          lfs: true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache Python dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements_github.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          set -euxo pipefail
          python -m pip install --upgrade pip
          pip install -r requirements_github.txt

      - name: Ensure data dir
        run: mkdir -p data

      # pull the latest DB/IDs from the dedicated LFS-backed `data` branch
      - name: Checkout data branch (LFS)
        uses: actions/checkout@v4
        with:
          path: _data_branch
          ref: data
          fetch-depth: 1
          lfs: true
        continue-on-error: true  # first run: branch may not exist

      - name: Restore previous DB/IDs from data branch (if present)
        run: |
          set -euxo pipefail
          if [ -d "_data_branch" ]; then
            if [ -f "_data_branch/data/polish_scientists.db" ]; then
              cp -f "_data_branch/data/polish_scientists.db" "data/polish_scientists.db"
              echo "Restored previous DB."
            else
              echo "No previous DB in data branch."
            fi
            if [ -f "_data_branch/data/polish_researchers_all.txt" ]; then
              cp -f "_data_branch/data/polish_researchers_all.txt" "data/polish_researchers_all.txt"
              echo "Restored previous IDs file."
            else
              echo "No previous IDs file in data branch."
            fi
          else
            echo "No data branch yet."
          fi

      - name: Check existing files
        run: |
          set -euxo pipefail
          echo "=== Workspace ==="; ls -la
          echo "=== data/ ==="; ls -la data || true
          if [ -f "data/polish_scientists.db" ]; then
            echo "DB size: $(du -h data/polish_scientists.db)"
            echo "DB rows: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Researchers;' 2>/dev/null || echo 'N/A')"
          fi
          if [ -f "data/polish_researchers_all.txt" ]; then
            echo "IDs lines: $(wc -l < data/polish_researchers_all.txt)"
          fi

      - name: Run ORCID data collection
        env:
          BATCH_SIZE: ${{ github.event.inputs.batch_size || '6250' }}
          MAX_API_CALLS: ${{ github.event.inputs.max_api_calls || '25000' }}
          DB_PATH: 'data/polish_scientists.db'
          IDS_FILE: 'data/polish_researchers_all.txt'
        run: |
          set -euxo pipefail
          echo "🚀 Starting ORCID collection with batch size: $BATCH_SIZE"
          python orcid_collector_github.py

      - name: Check results
        run: |
          set -euxo pipefail
          echo "=== Results ==="
          if [ -f "data/polish_scientists.db" ]; then
            echo "Final DB size: $(du -h data/polish_scientists.db)"
            echo "Researchers: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Researchers;' 2>/dev/null || echo 'N/A')"
            echo "Institutions: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Institutions;' 2>/dev/null || echo 'N/A')"
            echo "Publications: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Publications;' 2>/dev/null || echo 'N/A')"
          else
            echo "❌ No DB produced"
          fi

      # --- Publish ONLY the latest snapshot to an orphan commit on branch `data` (Git LFS) ---
      - name: Publish to single-commit LFS branch `data`
        if: success() && hashFiles('data/polish_scientists.db') != ''
        run: |
          set -euxo pipefail

          PUBDIR=_publish_data
          rm -rf "$PUBDIR"
          mkdir -p "$PUBDIR"
          cd "$PUBDIR"

          # init a clean repo that points to the current repository
          git init
          git remote add origin "${{ github.server_url }}/${{ github.repository }}.git"

          # user for the commit
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # LFS
          git lfs install

          # create ORPHAN commit (no parent) so the branch has exactly one commit
          git checkout --orphan data
          # bring in files
          mkdir -p data
          cp -f ../data/polish_scientists.db data/
          if [ -f ../data/polish_researchers_all.txt ]; then
            cp -f ../data/polish_researchers_all.txt data/
          fi

          # track DB with LFS (and optional IDs if you want)
          git lfs track "data/*.db"
          echo "/data/" > .gitignore
          sed -i '1s|^|!data/\n|g' .gitignore  # keep data/

          # ensure .gitattributes is committed so LFS applies
          git add .gitattributes || true
          git add -f data/polish_scientists.db
          [ -f data/polish_researchers_all.txt ] && git add -f data/polish_researchers_all.txt || true
          # keep a tiny README to explain the branch
          echo "# Latest ORCID DB snapshot (LFS)\nThis branch always contains a single commit with the most recent files." > README.md
          git add README.md

          git commit -m "Publish latest DB snapshot [orphan, single-commit]"

          # force push (replace branch history with this single commit)
          git push -f origin HEAD:data

          cd ..
          echo "✅ Published latest snapshot to branch 'data' (single-commit, LFS)."

      - name: Collection summary
        run: |
          {
            echo "## 🎯 ORCID Collection Summary"
            echo
            if [ -f "data/polish_scientists.db" ]; then
              researchers_count=$(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Researchers;' 2>/dev/null || echo 'Unknown')
              institutions_count=$(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Institutions;' 2>/dev/null || echo 'Unknown')
              publications_count=$(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Publications;' 2>/dev/null || echo 'Unknown')
              db_size=$(du -h data/polish_scientists.db | cut -f1)
              echo "- **Researchers processed:** $researchers_count"
              echo "- **Institutions:** $institutions_count"
              echo "- **Publications:** $publications_count"
              echo "- **Database size:** $db_size"
            else
              echo "- **Status:** ❌ Collection failed - no database generated"
            fi
            echo
            echo "The 'data' branch always contains a single LFS-backed snapshot of the latest DB."
          } >> "$GITHUB_STEP_SUMMARY"
