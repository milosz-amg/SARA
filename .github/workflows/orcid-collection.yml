name: ORCID Polish Researchers Collection

on:
  schedule:
    # Run daily at 2 AM UTC (avoids peak hours)
    - cron: '0 2 * * *'
  workflow_dispatch:
    # Allow manual trigger
    inputs:
      batch_size:
        description: 'Number of researchers to process'
        required: false
        default: '6250'
        type: string
      max_api_calls:
        description: 'Maximum API calls per run'
        required: false
        default: '25000'
        type: string

jobs:
  collect-orcid-data:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours max
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements_github.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements_github.txt
        
    - name: Get latest successful run ID
      id: latest-run
      run: |
        # Get the latest successful workflow run (excluding current run)
        LATEST_RUN=$(gh run list --workflow="orcid-collection.yml" --status=completed --limit=1 --json databaseId --jq '.[0].databaseId')
        echo "latest_run_id=$LATEST_RUN" >> $GITHUB_OUTPUT
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      continue-on-error: true
      
    - name: Download previous database
      uses: actions/download-artifact@v4
      with:
        name: polish-scientists-database
        path: data/
        run-id: ${{ steps.latest-run.outputs.latest_run_id }}
      continue-on-error: true  # Don't fail if no previous database exists
      
    - name: Download researcher IDs file
      uses: actions/download-artifact@v4
      with:
        name: polish-researchers-ids
        path: data/
        run-id: ${{ steps.latest-run.outputs.latest_run_id }}
      continue-on-error: true  # Don't fail if no previous IDs file exists
      
    - name: Check existing files
      run: |
        echo "=== Workspace contents ==="
        ls -la
        echo "=== Data folder contents ==="
        ls -la data/ || echo "No data folder found"
        
        # Check database
        if [ -f "data/polish_scientists.db" ]; then
          echo "📊 Database size: $(du -h data/polish_scientists.db)"
          echo "📊 Database records: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Researchers;' 2>/dev/null || echo 'No Researchers table')"
        else
          echo "📄 No existing database found"
        fi
        
        # Check IDs file
        if [ -f "data/polish_researchers_all.txt" ]; then
          echo "📋 IDs file size: $(wc -l < data/polish_researchers_all.txt) lines"
        else
          echo "📄 No IDs file found"
        fi
        
    - name: Run ORCID data collection
      env:
        BATCH_SIZE: ${{ github.event.inputs.batch_size || '6250' }}
        MAX_API_CALLS: ${{ github.event.inputs.max_api_calls || '25000' }}
        DB_PATH: 'data/polish_scientists.db'
        IDS_FILE: 'data/polish_researchers_all.txt'
      run: |
        echo "🚀 Starting ORCID collection with batch size: $BATCH_SIZE"
        python orcid_collector_github.py
        
    - name: Check results
      run: |
        echo "=== Collection Results ==="
        if [ -f "data/polish_scientists.db" ]; then
          echo "📊 Final database size: $(du -h data/polish_scientists.db)"
          echo "📊 Total researchers: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Researchers;' 2>/dev/null || echo 'Error reading database')"
          echo "📊 Total institutions: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Institutions;' 2>/dev/null || echo 'Error reading database')"
          echo "📊 Total publications: $(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Publications;' 2>/dev/null || echo 'Error reading database')"
        else
          echo "❌ No database file found"
        fi
        
    - name: Upload database artifact
      uses: actions/upload-artifact@v4
      with:
        name: polish-scientists-database
        path: data/polish_scientists.db
        retention-days: 90  # Keep for 3 months
        
    - name: Upload researcher IDs artifact
      uses: actions/upload-artifact@v4
      with:
        name: polish-researchers-ids
        path: data/polish_researchers_all.txt
        retention-days: 90
        
    - name: Upload logs (if any)
      uses: actions/upload-artifact@v4
      with:
        name: collection-logs-${{ github.run_number }}
        path: "*.log"
        retention-days: 30
      continue-on-error: true
      
    - name: Collection summary
      run: |
        echo "## 🎯 ORCID Collection Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        if [ -f "data/polish_scientists.db" ]; then
          researchers_count=$(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Researchers;' 2>/dev/null || echo 'Unknown')
          echo "- **Researchers processed:** $researchers_count" >> $GITHUB_STEP_SUMMARY
          
          institutions_count=$(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Institutions;' 2>/dev/null || echo 'Unknown')
          echo "- **Institutions:** $institutions_count" >> $GITHUB_STEP_SUMMARY
          
          publications_count=$(sqlite3 data/polish_scientists.db 'SELECT COUNT(*) FROM Publications;' 2>/dev/null || echo 'Unknown')
          echo "- **Publications:** $publications_count" >> $GITHUB_STEP_SUMMARY
          
          db_size=$(du -h data/polish_scientists.db | cut -f1)
          echo "- **Database size:** $db_size" >> $GITHUB_STEP_SUMMARY
        else
          echo "- **Status:** ❌ Collection failed - no database generated" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Next run scheduled for tomorrow at 2 AM UTC" >> $GITHUB_STEP_SUMMARY