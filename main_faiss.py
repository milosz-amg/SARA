import os
from embedder import build_faiss_index
from search import search_faiss
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# ÅšcieÅ¼ki
DATA_PATH = "data/researchers/researchers.json"
INDEX_PATH = "faiss_index/uam.index"

# Upewnij siÄ™, Å¼e katalog na indeks istnieje
os.makedirs("faiss_index", exist_ok=True)

# Tworzenie indeksu FAISS
print("ğŸ”§ TworzÄ™ indeks FAISS...")
build_faiss_index(DATA_PATH, INDEX_PATH)
print("âœ… Indeks gotowy!")

# Inicjalizacja klienta OpenAI
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Funkcja gÅ‚Ã³wna: pytanie + wyszukiwanie + odpowiedÅº
def ask_with_context(query):
    print(f"ğŸ” Szukam kontekstu dla pytania: {query}")
    results = search_faiss(query, INDEX_PATH, top_k=3)

    context = ""
    for res in results:
        context += f"{res['name']} ({res['affiliation']}): {', '.join(res['research_areas'])}\n"
        for project in res.get("projects", []):
            context += f"- {project['title']} ({project['years']}) | {project['grant_amount']} PLN\n"
        context += f"Å¹rÃ³dÅ‚o: {res['source']}\n\n"

    prompt = f"""
KONTEKST:
{context}

PYTANIE:
{query}

ODPOWIEDÅ¹:
"""

    print("ğŸ“¡ WysyÅ‚am do modelu GPT...")
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3
    )

    answer = response.choices[0].message.content
    return answer

def print_results(results):
    for res in results:
        print(f"\nğŸ”¹ {res['name']} ({res['affiliation']})")
        print(f"   Dziedziny: {', '.join(res['research_areas'])}")
        for project in res.get("projects", []):
            print(f"   ğŸ“ Projekt: {project['title']} ({project['years']}) â€“ {project['grant_amount']} PLN")
        print(f"   Å¹rÃ³dÅ‚o: {res['source']}")

if __name__ == "__main__":
    question = "KtÃ³rzy naukowcy z WMiI UAM zajmujÄ… siÄ™ logikÄ… rozmytÄ…?"
    results = search_faiss(question, INDEX_PATH, top_k=3)
    print_results(results)
